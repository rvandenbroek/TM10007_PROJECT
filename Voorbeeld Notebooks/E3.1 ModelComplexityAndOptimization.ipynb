{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TM10007: Machine learning\n",
    "## Week 3, lecture 2: Model complexity and optimization\n",
    "#### Author: Martijn P. A. Starmans\n",
    "\n",
    "In this exercise, you will learn how to use support vector machines and kernels using scikit learn.\n",
    "\n",
    "For more of these methods, visit https://scikit-learn.org/stable/modules/svm.html, https://scikit-learn.org/stable/modules/kernel_approximation.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "uGzIQavJrIk2",
    "outputId": "64e106c6-715b-47b9-db8d-a8e41a5e62ae"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMxkvj70rPMi"
   },
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Classifiers and kernels\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Regularization\n",
    "from sklearn.linear_model import Lasso, RidgeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# For the text classification dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from time import time\n",
    "\n",
    "# Functions for plotting ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndDvb37erIk8"
   },
   "outputs": [],
   "source": [
    "# Some functions we will use\n",
    "def colorplot(clf, ax, x, y, h=100, precomputer=None):\n",
    "    '''\n",
    "    Overlay the decision areas as colors in an axes.\n",
    "    \n",
    "    Input:\n",
    "        clf: trained classifier\n",
    "        ax: axis to overlay color mesh on\n",
    "        x: feature on x-axis\n",
    "        y: feature on y-axis\n",
    "        h(optional): steps in the mesh\n",
    "    '''\n",
    "    # Create a meshgrid the size of the axis\n",
    "    xstep = (x.max() - x.min() ) / 20.0\n",
    "    ystep = (y.max() - y.min() ) / 20.0\n",
    "    x_min, x_max = x.min() - xstep, x.max() + xstep\n",
    "    y_min, y_max = y.min() - ystep, y.max() + ystep\n",
    "    h = max((x_max - x_min, y_max - y_min))/h\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    features = np.c_[xx.ravel(), yy.ravel()]\n",
    "    if precomputer is not None:\n",
    "        if type(precomputer) is RBFSampler:\n",
    "            features = precomputer.transform(features)\n",
    "        elif precomputer is rbf_kernel:\n",
    "            features = rbf_kernel(features, X)\n",
    "            \n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(features)\n",
    "    elif hasattr(clf, \"predict_proba\"):\n",
    "        Z = clf.predict_proba(features)\n",
    "    else:\n",
    "        Z = clf.predict(features)\n",
    "        \n",
    "    if len(Z.shape) > 1:\n",
    "        Z = Z[:, 1]\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    cm = plt.cm.RdBu_r\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "    del xx, yy, x_min, x_max, y_min, y_max, Z, cm\n",
    "    \n",
    "def load_breast_cancer(n_features=2):\n",
    "    '''\n",
    "    Load the sklearn breast data set, but reduce the number of features with PCA.\n",
    "    '''\n",
    "    data = ds.load_breast_cancer()\n",
    "    x = data['data']\n",
    "    y = data['target']\n",
    "    \n",
    "    p = PCA(n_components=n_features)\n",
    "    p = p.fit(x)\n",
    "    x = p.transform(x)\n",
    "    return x, y\n",
    "\n",
    "def load_boston(n_features=1):\n",
    "    '''\n",
    "    Load the sklearn boston data set, but reduce the number of features with PCA.\n",
    "    '''\n",
    "    data = ds.load_boston()\n",
    "    x = data['data']\n",
    "    y = data['target']\n",
    "    \n",
    "    p = PCA(n_components=n_features)\n",
    "    p = p.fit(x)\n",
    "    x = p.transform(x)\n",
    "    return x, y\n",
    "\n",
    "def load_diabetes(n_features=1):\n",
    "    '''\n",
    "    Load the sklearn bdiabetes data set, but reduce the number of features with PCA.\n",
    "    '''\n",
    "    data = ds.load_diabetes()\n",
    "    x = data['data']\n",
    "    y = data['target']\n",
    "    \n",
    "    p = PCA(n_components=n_features)\n",
    "    p = p.fit(x)\n",
    "    x = p.transform(x)\n",
    "    return x, y\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores  = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "def load_text_dataset(N_features=100):\n",
    "    '''\n",
    "    Load dataset for classifying text documents by topic.\n",
    "    '''\n",
    "    categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc'\n",
    "    ]\n",
    "\n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "    print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "    print(categories if categories else \"all\")\n",
    "\n",
    "    data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                    shuffle=True, random_state=42,\n",
    "                                    remove=remove)\n",
    "\n",
    "    data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                                   shuffle=True, random_state=42,\n",
    "                                   remove=remove)\n",
    "    print('data loaded')\n",
    "\n",
    "    # order of labels in `target_names` can be different from `categories`\n",
    "    target_names = data_train.target_names\n",
    "\n",
    "\n",
    "    def size_mb(docs):\n",
    "        return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "\n",
    "    data_train_size_mb = size_mb(data_train.data)\n",
    "    data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "    print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "        len(data_train.data), data_train_size_mb))\n",
    "    print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "        len(data_test.data), data_test_size_mb))\n",
    "    print(\"%d categories\" % len(target_names))\n",
    "    print()\n",
    "\n",
    "    # split a training set and a test set\n",
    "    y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "    t0 = time()\n",
    "    use_hashing = False\n",
    "    if use_hashing:\n",
    "        vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
    "                                       n_features=2 ** 16)\n",
    "        X_train = vectorizer.transform(data_train.data)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                     stop_words='english')\n",
    "        X_train = vectorizer.fit_transform(data_train.data)\n",
    "    duration = time() - t0\n",
    "    print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    print()\n",
    "\n",
    "    print(\"Extracting features from the test data using the same vectorizer\")\n",
    "    t0 = time()\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    duration = time() - t0\n",
    "    print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "    print()\n",
    "\n",
    "    # mapping from integer feature name to original token string\n",
    "    if use_hashing:\n",
    "        feature_names = None\n",
    "    else:\n",
    "        feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    if N_features < X_train.shape[1]:\n",
    "        print(\"Extracting %d best features by a chi-squared test\" %\n",
    "              N_features)\n",
    "        t0 = time()\n",
    "        ch2 = SelectKBest(chi2, k=N_features)\n",
    "        X_train = ch2.fit_transform(X_train, y_train)\n",
    "        X_test = ch2.transform(X_test)\n",
    "        if feature_names:\n",
    "            # keep selected feature names\n",
    "            feature_names = [feature_names[i] for i\n",
    "                             in ch2.get_support(indices=True)]\n",
    "        print(\"done in %fs\" % (time() - t0))\n",
    "        print()\n",
    "    \n",
    "    if feature_names:\n",
    "        feature_names = np.asarray(feature_names)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_score, y_truth):\n",
    "    '''\n",
    "    Plot an ROC curve.\n",
    "    '''\n",
    "    # Only take scores for class = 1\n",
    "    y_score = y_score[:, 1]\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve(y_truth, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first create again three example datasets to play with and plot the feature distributions in scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h2F8gyQ0rIk-",
    "outputId": "c7d1dfeb-9c57-4119-a169-bbde47b57f14"
   },
   "outputs": [],
   "source": [
    "# Load and plot three different classification datasets\n",
    "X2, Y2 = ds.make_classification(n_samples=100, n_features=2, n_redundant=0,\n",
    "                                n_informative=1,\n",
    "                                n_clusters_per_class=1)\n",
    "fig = plt.figure(figsize=(24,8))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.set_title(\"One informative feature, one cluster per class\", fontsize='small')\n",
    "ax.scatter(X2[:, 0], X2[:, 1], marker='o', c=Y2,\n",
    "            s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "\n",
    "X3, Y3 = ds.make_blobs(n_samples=100, n_features=2, centers=2, cluster_std=5)\n",
    "ax = fig.add_subplot(132)\n",
    "ax.set_title(\"Two blobs, two classes\", fontsize='small')\n",
    "ax.scatter(X3[:, 0], X3[:, 1], marker='o', c=Y3,\n",
    "            s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "\n",
    "X4, Y4 = load_breast_cancer()\n",
    "ax = fig.add_subplot(133)\n",
    "ax.set_title(\"A more complicated problem\", fontsize='small')\n",
    "ax.scatter(X4[:, 0], X4[:, 1], marker='o', c=Y4,\n",
    "            s=25, edgecolor='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CPd2U_0ArIlB",
    "outputId": "1f41c4d9-c755-4a67-b853-3ea3e39fea7e"
   },
   "source": [
    "## Regularization: random forest\n",
    "Let us first check what a random forest with a varying number of trees (1, 5, 200) would do on each dataset when using a single train-test split in each dataset. Note that we fixed all randomness, so you will get the same answer every time: you would not normally do this in a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "5yVUZZ_hrIlF",
    "outputId": "3764851c-1b8b-4190-b928-f3755d6fa511"
   },
   "outputs": [],
   "source": [
    "# Construct classifiers\n",
    "clsfs = [RandomForestClassifier(n_estimators=1, random_state=42),\n",
    "         RandomForestClassifier(n_estimators=5, random_state=42),\n",
    "         RandomForestClassifier(n_estimators=200, random_state=42)]\n",
    "\n",
    "\n",
    "# Create lists of datasets to loop over\n",
    "Xs = [X2, X3, X4]\n",
    "Ys = [Y2, Y3, Y4]\n",
    "\n",
    "# First make plot without classifiers:\n",
    "num = 0\n",
    "fig = plt.figure(figsize=(24,8*len(clsfs)))\n",
    "for X, Y in zip(Xs, Ys):\n",
    "    ax = fig.add_subplot(7, 3, num + 1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
    "        s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "    num += 1\n",
    "    \n",
    "# Now use the classifiers on all datasets\n",
    "for clf in clsfs:\n",
    "    for X, Y in zip(Xs, Ys):\n",
    "        # Split data in training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        ax = fig.add_subplot(7, 3, num + 1)\n",
    "        ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
    "            s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "        colorplot(clf, ax, X[:, 0], X[:, 1])\n",
    "        y_pred = clf.predict(X_test)\n",
    "        t = (\"Misclassified: %d / %d\" % ((y_test != y_pred).sum(), y_test.shape[0]))\n",
    "        ax.set_title(t)\n",
    "        num += 1\n",
    "        \n",
    "# Note: you may get a FutureWarning, which you can for now just ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YJKZFrHVrIlH",
    "outputId": "1559c3fb-4cbf-454a-e65c-aea229070484"
   },
   "source": [
    "The complexity of the problem varies from the left to the right. We observe that:\n",
    "- Left: all random forests work equally well. However, the decision boundary with a large number of trees becomes more complicated, and may not generalize as well as the simple boundary when only using a single tree.\n",
    "- Middle: the single tree forest does not perform so well. The forests with 5 and 200 trees perform similar, but the one with 5 trees performs a bit better. Based on performance, 5 trees would thus be most suitable. Additionally, you may favour a less complex solution if it performs similar.\n",
    "- Right: the problem is very complex, resulting in this case in the more complex 200 tree forest performing the best. However, even more trees may let it perform even better...\n",
    "\n",
    "So which classifier would you pick for each problem, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization: L1 and L2 norm\n",
    "In the lectures, we have seen the L1 and L2 norm for regularization. These can be used in combination with a linear classifier in the Lasso and Ridge classifiers from sklearn. Both have a parameter \\alpha which controls the weight of the regularization term. Let us start by using the Ridge classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a larger dataset with more features\n",
    "X_train, X_test, y_train, y_test = load_text_dataset(N_features=1000)\n",
    "\n",
    "# This dataset contains samples of different text types. We have extracte two classes: atheist texts and religious texts.\n",
    "# Originally, this dataset contained thousands of features. Using univariate selection, we can quickly select a subset of 1000.\n",
    "\n",
    "# Display the weights and compute error for multiple values for alpha\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-10, -1, n_alphas)\n",
    "\n",
    "# Construct classifiers\n",
    "coefs = []\n",
    "accuracies = []\n",
    "times = []\n",
    "for a in alphas:\n",
    "    # Fit classifier\n",
    "    clf = RidgeClassifier(alpha=a, fit_intercept=False)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    duration = time() - t0\n",
    "    y_pred = clf.predict(X_test)\n",
    "    message = (\"\\t Misclassified: %d / %d\" % ((y_test != y_pred).sum(), y_test.shape[0]))\n",
    "    print(message)\n",
    "    \n",
    "    # Append statistics\n",
    "    accuracy = float((y_test != y_pred).sum()) / float(y_test.shape[0])\n",
    "    times.append(duration)\n",
    "    accuracies.append(accuracy)\n",
    "    coefs.append(clf.coef_)\n",
    "\n",
    "# #############################################################################\n",
    "# Display results\n",
    "\n",
    "# Weights\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, np.squeeze(coefs))\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Performance\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, accuracies)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('accuracies')\n",
    "plt.title('Performance as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Times\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, times)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('times (s)')\n",
    "plt.title('Fitting time as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Note: you may get a FutureWarning, which you can for now just ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe:\n",
    "- With respect to the value of the weights?\n",
    "- With respect to the accuracy on the test set of the classifier?\n",
    "- With respect to the times of fitting?\n",
    "\n",
    "What would you conclude about when and how to use L2 regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now do the same for the Lasso estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct classifiers\n",
    "coefs = []\n",
    "accuracies = []\n",
    "times = []\n",
    "for a in alphas:\n",
    "    # Fit classifier\n",
    "    clf = Lasso(alpha=a, fit_intercept=False)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    duration = time() - t0\n",
    "    y_pred = clf.predict(X_test)\n",
    "    message = (\"\\t Misclassified: %d / %d\" % ((y_test != y_pred).sum(), y_test.shape[0]))\n",
    "    print(message)\n",
    "    \n",
    "    # Append statistics\n",
    "    accuracy = float((y_test != y_pred).sum()) / float(y_test.shape[0])\n",
    "    times.append(duration)\n",
    "    accuracies.append(accuracy)\n",
    "    coefs.append(clf.coef_)\n",
    "\n",
    "# #############################################################################\n",
    "# Display results\n",
    "\n",
    "# Weights\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, np.squeeze(coefs))\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Lasso coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Performance\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, accuracies)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('accuracies')\n",
    "plt.title('Performance as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Times\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, times)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('times (s)')\n",
    "plt.title('Fitting time as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# Note: you may get a FutureWarning, which you can for now just ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe:\n",
    "- With respect to the value of the weights?\n",
    "- With respect to the accuracy on the test set of the classifier?\n",
    "- With respect to the times of fitting?\n",
    "\n",
    "What would you conclude about when and how to use L1 regularization / Lasso? How do the L2 and L1 regularization compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso estimator encourages weights to go to zero. Features with a weight of zero do not contribute to the final prediction. Thus, the Lasso estimator can also be used as a feature selection method. In sklearn, this is implemented throught the SelectFromModel module. Let us demonstrate how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataset with many uninformative features\n",
    "X, Y = ds.make_classification(n_samples=100, n_features=100, n_redundant=0,\n",
    "                              n_informative=2,\n",
    "                              n_clusters_per_class=1,\n",
    "                              random_state=42)\n",
    "\n",
    "# Split in training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Fit a simple LDA without feature selection and plot an ROC curve\n",
    "clf = LDA()\n",
    "clf.fit(X_train, y_train)\n",
    "y_score = clf.predict_proba(X_test)\n",
    "plot_roc_curve(y_score, y_test)\n",
    "\n",
    "\n",
    "# Now first use the selectfrom model module. Select all features with a weight above the median.\n",
    "selector = SelectFromModel(estimator=Lasso(alpha=10**(-10), random_state=42), threshold='median')\n",
    "selector.fit(X_train, y_train)\n",
    "n_original = X_train.shape[1]\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "n_selected = X_train.shape[1]\n",
    "print(f\"Selected {n_selected} from {n_original} features.\")\n",
    "\n",
    "# Fit the LDA on selected features\n",
    "clf = LDA()\n",
    "clf.fit(X_train, y_train)\n",
    "y_score = clf.predict_proba(X_test)\n",
    "plot_roc_curve(y_score, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply selecting half of the features, which still includes 48 non-informative features, has resulted in our LDA now performing much better on the test dataset than when using all original features! Whether to use the Lasso regularization or another feature selection method, depends on your dataset. Note that we have now fixed the regularization weight parameter to 10**(-10), which you would normally have to tune to your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bRISjuJ2rIlJ",
    "outputId": "4879949a-bd00-48ed-daeb-7ca9fb4059ec"
   },
   "source": [
    "## Learning Curves\n",
    "\n",
    "As you can see above, hyperparameter tuning is important, and the optimal choice may vary per problem. Let us now demonstrate this using learning curves. This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 967
    },
    "colab_type": "code",
    "id": "PNMw4XoMrIlL",
    "outputId": "f5aecbfd-3d20-46f8-ae0d-acd1c447daac"
   },
   "outputs": [],
   "source": [
    "# Largely based on example from: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\n",
    "\n",
    "# First make plot without classifiers:\n",
    "num = 0\n",
    "fig = plt.figure(figsize=(24,8*len(clsfs)))\n",
    "for X, Y in zip(Xs, Ys):\n",
    "    ax = fig.add_subplot(7, 3, num + 1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
    "        s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "    num += 1\n",
    "    \n",
    "        \n",
    "# Create a cross-validation object\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "# Now use the classifiers on all datasets\n",
    "for clf in clsfs:\n",
    "    for X, Y in zip(Xs, Ys):\n",
    "        # Split data in training and testing\n",
    "        title = str(type(clf))\n",
    "        ax = fig.add_subplot(7, 3, num + 1)\n",
    "        plot_learning_curve(clf, title, X, Y, ax, ylim=(0.3, 1.01), cv=cv)\n",
    "        num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7J2dqozsrIlN"
   },
   "source": [
    "What do the learning curves tell you? Can they help in deciding which classifier to use for each dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "We saw that the number of trees for a random forest heavily influences the performance and complexity. Let us try to automatically optimize the number of trees using a randomized search. This may take a minute or two. Note that we again fixed the random states, which you should not do normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our parameter to optimize is the number of estimators, which we vary uniformlybetween 1 and 400\n",
    "param_distributions = {'n_estimators': randint(1, 400)}\n",
    "\n",
    "\n",
    "# First make plot without classifiers:\n",
    "num = 0\n",
    "fig = plt.figure(figsize=(24,8*len(clsfs)))\n",
    "for X, Y in zip(Xs, Ys):\n",
    "    ax = fig.add_subplot(2, 3, num + 1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
    "        s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "    num += 1\n",
    "    \n",
    "# Now use the classifiers on all datasets\n",
    "fitted_clfs = list()\n",
    "for X, Y in zip(Xs, Ys):\n",
    "    # Split data in training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Within a 5-fold cross-validation, try out 20 different number of trees\n",
    "    clf = RandomizedSearchCV(RandomForestClassifier(), param_distributions, cv=5, n_iter=20, random_state=42)\n",
    "    \n",
    "    # Fit the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Save for next part\n",
    "    fitted_clfs.append(clf)\n",
    "    \n",
    "    # Plotting\n",
    "    ax = fig.add_subplot(2, 3, num + 1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
    "        s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "    colorplot(clf, ax, X[:, 0], X[:, 1])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    t = (\"Misclassified: %d / %d\" % ((y_test != y_pred).sum(), y_test.shape[0]))\n",
    "    ax.set_title(t)\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the results of the fitting by looking at the several object within the fitted ``RandomizedSearchCV``object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at all the results: only for the first problem\n",
    "print(fitted_clfs[0].cv_results_)\n",
    "\n",
    "# Get the best estimator and best parameters belonging to that estimator\n",
    "for num, clf in enumerate(fitted_clfs):\n",
    "    print(f'\\n The best estimator and parameters for dataset {num} are:')\n",
    "    print(f'\\t {clf.best_estimator_}')\n",
    "    print(f'\\t {clf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the ``RandomizedSearchCV`` selects the best estimator and best parameters purely based on performance, not on aspects such as generalizability and complexity. Moreover, there may be several solutions performing equally, in which case a random one is picked, or similar with minor differences. Hence it may be that the selected solution is very complex, while the second best solution performs only say 0.0000001% lower and is much less complex, and thus would be a better choice. Thus, be careful in your optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifiers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
