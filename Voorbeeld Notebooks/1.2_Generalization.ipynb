{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of 1_2_Generalization.ipynb","provenance":[{"file_id":"16qp7x5T_H_bantqxEp5hjNT-wPYrkuwK","timestamp":1584628427320},{"file_id":"1xT6og9AzSpJy4I0alma1F2WHSkDgN2Wq","timestamp":1584628404279}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2+"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cIqdvO3AKJmJ","colab_type":"text"},"source":["# TM10007: Machine learning\n","## Week 1, lecture 2: Generalization\n","#### Author: Hakim C. Achterberg\n","\n","In this exercise, you will have a look at generalization and experimental setup.\n","\n","For documentation about how to implement these methods in Python have a look at: https://scikit-learn.org/stable/model_selection.html\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uGzIQavJrIk2","colab":{}},"source":["!pip install sklearn numpy matplotlib"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xMxkvj70rPMi","colab":{}},"source":["# General packages\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import datasets as ds\n","import seaborn\n","\n","# Classifiers\n","from sklearn import model_selection\n","from sklearn import metrics\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ndDvb37erIk8","colab":{}},"source":["# Some functions we will use\n","from sklearn.decomposition import PCA\n","\n","def colorplot(clf, ax, x, y, h=100):\n","    '''\n","    Overlay the decision areas as colors in an axes.\n","    \n","    Input:\n","        clf: trained classifier\n","        ax: axis to overlay color mesh on\n","        x: feature on x-axis\n","        y: feature on y-axis\n","        h(optional): steps in the mesh\n","    '''\n","    # Create a meshgrid the size of the axis\n","    xstep = (x.max() - x.min() ) / 20.0\n","    ystep = (y.max() - y.min() ) / 20.0\n","    x_min, x_max = x.min() - xstep, x.max() + xstep\n","    y_min, y_max = y.min() - ystep, y.max() + ystep\n","    h = max((x_max - x_min, y_max - y_min))/h\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n","                         np.arange(y_min, y_max, h))\n","    \n","    # Plot the decision boundary. For that, we will assign a color to each\n","    # point in the mesh [x_min, x_max]x[y_min, y_max].\n","    if hasattr(clf, \"decision_function\"):\n","        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n","    else:\n","        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n","    if len(Z.shape) > 1:\n","        Z = Z[:, 1]\n","    \n","    # Put the result into a color plot\n","    cm = plt.cm.RdBu_r\n","    Z = Z.reshape(xx.shape)\n","    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n","    del xx, yy, x_min, x_max, y_min, y_max, Z, cm\n","    \n","def load_breast_cancer(n_features=2):\n","    '''\n","    Load the sklearn breast data set, but reduce the number of features with PCA.\n","    '''\n","    data = ds.load_breast_cancer()\n","    x = data['data']\n","    y = data['target']\n","    \n","    p = PCA(n_components=n_features)\n","    p = p.fit(x)\n","    x = p.transform(x)\n","    return x, y\n","\n","def load_boston(n_features=1):\n","    '''\n","    Load the sklearn boston data set, but reduce the number of features with PCA.\n","    '''\n","    data = ds.load_boston()\n","    x = data['data']\n","    y = data['target']\n","    \n","    p = PCA(n_components=n_features)\n","    p = p.fit(x)\n","    x = p.transform(x)\n","    return x, y\n","\n","def load_diabetes(n_features=1):\n","    '''\n","    Load the sklearn bdiabetes data set, but reduce the number of features with PCA.\n","    '''\n","    data = ds.load_diabetes()\n","    x = data['data']\n","    y = data['target']\n","    \n","    p = PCA(n_components=n_features)\n","    p = p.fit(x)\n","    x = p.transform(x)\n","    return x, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EJAyIYZ1KJmc","colab_type":"text"},"source":["Let us first create again three example datasets to play with and plot the feature distributions\n","in scatter plots."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h2F8gyQ0rIk-","colab":{}},"source":["# Create a noise dataset\n","X2, y2 = ds.make_moons(n_samples=1000, noise=0.4, random_state=0)\n","\n","# Add extra external validation set\n","X3, y3 = ds.make_moons(n_samples=5000, noise=0.4, random_state=42)\n","\n","\n","fig = plt.figure(figsize=(24,8))\n","ax = fig.add_subplot(131)\n","ax.set_title(\"Noisy moon, entire dataset\", fontsize='small')\n","ax.scatter(X2[:, 0], X2[:, 1], marker='o', c=y2,\n","           s=25, edgecolor='k', cmap=plt.cm.Paired)\n","\n","# Split the dataset in train and test part\n","X2_train, X2_test, y2_train, y2_test = model_selection.train_test_split(X2, y2, test_size=0.5, stratify=y2)\n","\n","ax = fig.add_subplot(132)\n","ax.set_title(\"Training data\", fontsize='small')\n","ax.scatter(X2_train[:, 0], X2_train[:, 1], marker='o', c=y2_train,\n","           s=25, edgecolor='k', cmap=plt.cm.Paired)\n","\n","ax = fig.add_subplot(133)\n","ax.set_title(\"Test data\", fontsize='small')\n","ax.scatter(X2_test[:, 0], X2_test[:, 1], marker='o', c=y2_test,\n","           s=25, edgecolor='k', cmap=plt.cm.Paired)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJortQGVKJmi","colab_type":"text"},"source":["## Attempt at classification using a kNN\n","\n","As can be seen the generated dataset has a non-linear decision boundary and has some class overlap. This makes the classification problem harder because simple models will fail to find a good separation. A simple linear boundary could not separate the classes very well.\n","\n","We will attempt to solve this problem with a kNN classifier. Let's train a few k-Nearest Neighbor classifiers and see the performance."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"U93HT4KzKJmj","colab_type":"code","colab":{}},"source":["from sklearn import neighbors\n","k_list = [1, 3, 7]\n","fig = plt.figure(figsize=(24,8*len(k_list)))\n","num = 0\n","    \n","for k in k_list:\n","    clf_knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n","    clf_knn.fit(X2_train, y2_train)\n","\n","    # Test the classifier on the training data and plot\n","    score_train = clf_knn.score(X2_train, y2_train)\n","\n","    num += 1\n","    ax = fig.add_subplot(len(k_list), 2, num)\n","    ax.set_title(f\"Training performance: accuracy {score_train}\")\n","    colorplot(clf_knn, ax, X2[:, 0], X2[:, 1], h=1000)\n","    ax.scatter(X2_train[:, 0], X2_train[:, 1], marker='o', c=y2_train,\n","               s=25, edgecolor='k', cmap=plt.cm.Paired)\n","\n","    # Test the classifier on the test data and plot\n","    score_test = clf_knn.score(X2_test, y2_test)\n","\n","    num += 1\n","    ax = fig.add_subplot(len(k_list), 2, num)\n","    ax.set_title(f\"Test performance: accuracy {score_test}\")\n","    colorplot(clf_knn, ax, X2[:, 0], X2[:, 1], h=1000)\n","    ax.scatter(X2_test[:, 0], X2_test[:, 1], marker='o', c=y2_test,\n","               s=25, edgecolor='k', cmap=plt.cm.Paired)\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MDYuhXZCKJmo","colab_type":"text"},"source":["You can clearly see that the 1-NN looks perfect on the training data but seen to not perform as well on the test data. We can conclude that it doesn't generalize very well. The 3-NN and 7-NN seem to perform worse on the training data, but better on the test data. This indicates that these classifiers are less prone to over-fitting and generalize better."]},{"cell_type":"markdown","metadata":{"id":"ZNw56royKJmp","colab_type":"text"},"source":["# Gauging generalizability\n","\n","We can try to see how much regularization (higher k) helps in for this dataset by plotting a curve. This might give un an idea for different parameters, how well the model generalizes."]},{"cell_type":"code","metadata":{"id":"7xSw3QsTKJmq","colab_type":"code","colab":{}},"source":["from sklearn import neighbors\n","    \n","train_scores = []\n","test_scores = []\n","k_list = list(range(1, 25, 2))\n","\n","for k in k_list:\n","    clf_knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n","    clf_knn.fit(X2_train, y2_train)\n","\n","    # Test the classifier on the training data and plot\n","    score_train = clf_knn.score(X2_train, y2_train)\n","    score_test = clf_knn.score(X2_test, y2_test)\n","    \n","    train_scores.append(score_train)\n","    test_scores.append(score_test)\n","    \n","fig = plt.figure(figsize=(8,8))\n","ax = fig.add_subplot(111)\n","ax.grid()\n","ax.plot(k_list, train_scores, 'o-', color=\"r\",\n","        label=\"Training score\")\n","ax.plot(k_list, test_scores, 'o-', color=\"g\",\n","        label=\"Test score\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tNt256bSKJmu","colab_type":"text"},"source":["You can see the lines converging around k=13, after that they fluctuate but stay fairly similar. It's hard to draw conclusions from a single point/line, because we do not have any confidence or statistical tests. But the line does give an indication that around k=15 seems decent value. To get a more clear idea, instead of a single split, we could perform a repeat random split and see the distribution of scores. This is a bit more work:"]},{"cell_type":"code","metadata":{"id":"VIthy89PKJmw","colab_type":"code","colab":{}},"source":["k_list = list(range(1, 26, 2))\n","all_train = []\n","all_test = []\n","\n","# Repeat the experiment 20 times, use 20 random splits in which class balance is retained\n","sss = model_selection.StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=0)\n","\n","for train_index, test_index in sss.split(X2, y2):\n","    train_scores = []\n","    test_scores = []\n","    \n","    split_X_train = X2[train_index]\n","    split_y_train = y2[train_index]\n","    split_X_test = X2[test_index]\n","    split_y_test = y2[test_index]\n","\n","    for k in k_list:\n","        clf_knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n","        clf_knn.fit(split_X_train, split_y_train)\n","\n","        # Test the classifier on the training data and plot\n","        score_train = clf_knn.score(split_X_train, split_y_train)\n","        score_test = clf_knn.score(split_X_test, split_y_test)\n","\n","        train_scores.append(score_train)\n","        test_scores.append(score_test)\n","        \n","    all_train.append(train_scores)\n","    all_test.append(test_scores)\n","    \n","\n","# Create numpy array of scores and calculate the mean and std\n","all_train = np.array(all_train)\n","all_test = np.array(all_test)\n","\n","train_scores_mean = all_train.mean(axis=0)\n","train_scores_std = all_train.std(axis=0)\n","\n","test_scores_mean = all_test.mean(axis=0)\n","test_scores_std = all_test.std(axis=0)\n","\n","# Plot the mean scores and the std as shading\n","fig = plt.figure(figsize=(8,8))\n","ax = fig.add_subplot(111)\n","ax.grid()\n","ax.fill_between(k_list, train_scores_mean - train_scores_std,\n","                     train_scores_mean + train_scores_std, alpha=0.1,\n","                     color=\"r\")\n","ax.fill_between(k_list, test_scores_mean - test_scores_std,\n","                     test_scores_mean + test_scores_std, alpha=0.1,\n","                     color=\"g\")\n","ax.plot(k_list, train_scores_mean, 'o-', color=\"r\",\n","        label=\"Training score\")\n","ax.plot(k_list, test_scores_mean, 'o-', color=\"g\",\n","        label=\"Test score\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KfHDik3-KJmz","colab_type":"text"},"source":["### Use AUC instead of Accuracy\n","\n","Adapt the code to display the AUC instead of the accuracy. You can use the following function to calculate the AUC: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\n","\n","To obtain the scores argument for the AUC, you can use the predict_proba method of the kNN classifier."]},{"cell_type":"code","metadata":{"id":"czvZ9VOmKJm1","colab_type":"code","colab":{}},"source":["k_list = list(range(1, 26, 2))\n","all_train = []\n","all_test = []\n","\n","# Repeat the experiment 20 times, use 20 random splits in which class balance is retained\n","sss = model_selection.StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=0)\n","\n","for train_index, test_index in sss.split(X2, y2):\n","    train_scores = []\n","    test_scores = []\n","    \n","    split_X_train = X2[train_index]\n","    split_y_train = y2[train_index]\n","    split_X_test = X2[test_index]\n","    split_y_test = y2[test_index]\n","\n","    for k in k_list:\n","        clf_knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n","        clf_knn.fit(split_X_train, split_y_train)\n","\n","        # Test the classifier on the training data and plot\n","        train_proba = clf_knn.predict_proba(split_X_train)[:, 1]\n","        test_proba = clf_knn.predict_proba(split_X_test)[:, 1]\n","        \n","        score_train = metrics.roc_auc_score(split_y_train, train_proba)\n","        score_test = metrics.roc_auc_score(split_y_test, test_proba)\n","        \n","\n","        train_scores.append(score_train)\n","        test_scores.append(score_test)\n","        \n","    all_train.append(train_scores)\n","    all_test.append(test_scores)\n","    \n","\n","# Create numpy array of scores and calculate the mean and std\n","all_train = np.array(all_train)\n","all_test = np.array(all_test)\n","\n","train_scores_mean = all_train.mean(axis=0)\n","train_scores_std = all_train.std(axis=0)\n","\n","test_scores_mean = all_test.mean(axis=0)\n","test_scores_std = all_test.std(axis=0)\n","\n","# Plot the mean scores and the std as shading\n","fig = plt.figure(figsize=(8,8))\n","ax = fig.add_subplot(111)\n","ax.grid()\n","ax.fill_between(k_list, train_scores_mean - train_scores_std,\n","                     train_scores_mean + train_scores_std, alpha=0.1,\n","                     color=\"r\")\n","ax.fill_between(k_list, test_scores_mean - test_scores_std,\n","                     test_scores_mean + test_scores_std, alpha=0.1,\n","                     color=\"g\")\n","ax.plot(k_list, train_scores_mean, 'o-', color=\"r\",\n","        label=\"Training score\")\n","ax.plot(k_list, test_scores_mean, 'o-', color=\"g\",\n","        label=\"Test score\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3udxMEOMKJm5","colab_type":"text"},"source":["# Setting up an experiment for kNN classification\n","\n","Now imagine we want to do a proper experiment. We want to:\n","* automatically find the optimal k hyperparameter\n","* estimate performance correctly\n","* have an indication of generalizability\n","\n","For this we would need to split the datain more than two parts:\n","* train set for fitting models\n","* validation set for testing hyperparamters (the different k values)\n","* test set for the final evaluation\n","\n","To limit the sample sets getting small, we would like to use cross validation."]},{"cell_type":"markdown","metadata":{"id":"5XVUK132KJm6","colab_type":"text"},"source":["## Fitting a k-NN  with optimal k\n","There are methods in scikit-learn to easily find the optimal hyper parameters using gridsearch and cross-validation. You can specify the classifier, parameters to search, cross-validation method and scoring measure yourself in an easy way:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"6qlP-QVKKJm7","colab_type":"code","colab":{}},"source":["# Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n","\n","# Specify the classifier\n","knn = neighbors.KNeighborsClassifier()\n","\n","# Specify the search range, this could be multiple parameters for more complex classifiers\n","parameters = {\n","    \"n_neighbors\": list(range(1, 26, 2))\n","}\n","\n","# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n","cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n","\n","# Create the grid search method, use area under ROC curve as scoring metric\n","# Too learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n","grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n","\n","# Do the entire search\n","grid_search.fit(X2_train, y2_train)\n","\n","# Show the complete results of the cross validation\n","pd.DataFrame(grid_search.cv_results_)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qfoTz3-KJm_","colab_type":"text"},"source":["### Change the CV and metric options\n","\n","You can play around with the above example. You could change the metrics use from AUC to F-score or another metric. How does this influence the resutsl? What about changing from a stratified to an unstratified cross-validation?"]},{"cell_type":"markdown","metadata":{"id":"nE7VUzvZKJnA","colab_type":"text"},"source":["## Perform the grid search in a cross-validation setting\n","\n","We will now wrap the previous grid-search example in another cross validation loop. In this loop we will split the data, fit the classifier, score the test data with the optimal classifier."]},{"cell_type":"code","metadata":{"id":"O56zSRuQKJnB","colab_type":"code","colab":{}},"source":["# Create a 20 fold stratified CV iterator\n","cv_20fold = model_selection.StratifiedKFold(n_splits=10)\n","results = []\n","best_n_neighbors = []\n","\n","# Loop over the folds\n","for validation_index, test_index in cv_20fold.split(X2, y2):\n","    # Split the data properly\n","    X_validation = X2[validation_index]\n","    y_validation = y2[validation_index]\n","    \n","    X_test = X2[test_index]\n","    y_test = y2[test_index]\n","    \n","    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n","    # Same as above\n","    parameters = {\"n_neighbors\": list(range(1, 26, 2))}\n","    knn = neighbors.KNeighborsClassifier()\n","    cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n","    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n","    grid_search.fit(X_validation, y_validation)\n","    \n","    # Get resulting classifier\n","    clf = grid_search.best_estimator_\n","    print(f'Best classifier: k={clf.n_neighbors}')\n","    best_n_neighbors.append(clf.n_neighbors)\n","    \n","    # Test the classifier on the test data\n","    probabilities = clf.predict_proba(X_test)\n","    scores = probabilities[:, 1]\n","    \n","    # Get the auc\n","    auc = metrics.roc_auc_score(y_test, scores)\n","    results.append({\n","        'auc': auc,\n","        'k': clf.n_neighbors,\n","        'set': 'test'\n","    })\n","    \n","    # Test the classifier on the validation data\n","    probabilities_validation = clf.predict_proba(X_validation)\n","    scores_validation = probabilities_validation[:, 1]\n","    \n","    # Get the auc\n","    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n","    results.append({\n","        'auc': auc_validation,\n","        'k': clf.n_neighbors,\n","        'set': 'validation'\n","    })\n","    \n","# Create results dataframe and plot it\n","results = pd.DataFrame(results)\n","seaborn.boxplot(y='auc', x='set', data=results)\n","\n","optimal_n = int(np.median(best_n_neighbors))\n","print(f\"The optimal N={optimal_n}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jXAIILM9KJnG","colab_type":"text"},"source":["### Extra steps\n","\n","If you would like to add another step to the method (e.g. feature scaling), where would you place that in the above example? How would you implement this? This will be the topic of next weeks exercises."]},{"cell_type":"markdown","metadata":{"id":"G5nwhVBtKJnI","colab_type":"text"},"source":["## Replication experiment\n","\n","The result of the classification looks fairly good, we have a high AUC and test van validation appear to be not too far apart. If we want to test the generalization more, we could use an independent replication set. We could quickly see if that works by fitting the method on the current data and applying to the new set."]},{"cell_type":"code","metadata":{"id":"PJDWyWCXKJnJ","colab_type":"code","colab":{}},"source":["# Use the optimal parameters without any tuning to validate the optimal classifier\n","clf = neighbors.KNeighborsClassifier(n_neighbors=optimal_n)\n","\n","# Fit on the entire dataset\n","clf.fit(X2, y2)\n","\n","# Test the classifier on the indepedent replication data\n","probabilities = clf.predict_proba(X3)\n","scores = probabilities[:, 1]\n","\n","# Get the auc\n","auc = metrics.roc_auc_score(y3, scores)\n","print(f'THe AUC on the replication set is {auc} using a {clf.n_neighbors}-NN classifier')"],"execution_count":0,"outputs":[]}]}