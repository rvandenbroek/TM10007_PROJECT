{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    " #Run this to use from colab environment\n",
    "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!\n",
    "\n",
    "\n",
    "This is a machine learning tool for the distinction of LGG and GBM, based on\n",
    "radiomic features.\n"
   ]
  },
  {
   "source": [
    "import math\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score, recall_score\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from brats.load_data import load_data\n",
    "# from SVM import SVM_algorithm\n",
    "# from SVM import SVM_hyper\n",
    "# from SVM import SVM_PCA"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Defenition preprocessing\n",
    "\n",
    "All relevant preprocessing functions are processed below\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "def dropnan(data, threshold):\n",
    "    '''First of all, cetrain strings and values in the dataset are turned into NaN.\n",
    "    With this function, features with more than a certain amount of NaN values will be\n",
    "    excluded from the dataset. The inputs are the contaminated dataset and the\n",
    "    threshold value. The output is the cleaned dataset. '''\n",
    "    # replace '#DIV/0!' and infinity values with NaN\n",
    "    data = data.replace(r'#DIV/0!', np.nan, regex=True)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan, regex=True)\n",
    "    # drop the features with more than threshold NaN's\n",
    "    data = data.dropna(thresh=threshold, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def imputation(train_data, test_data):\n",
    "    '''In order to substitute the NaN values rather then delete them, a kNN imputer function is\n",
    "    used to impute the missing data. This function is based on the train set and subsequently\n",
    "    applied on the test set. This ensures the model is completely trained on the train set rather\n",
    "    than the test set. The inputs are the trainset and the testset, the outputs are the same sets\n",
    "    with imputed values.\n",
    "    '''\n",
    "    # impute the still existing NaN's\n",
    "    imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "    imputed_train = imputer.fit_transform(train_data)\n",
    "    imputed_test = imputer.transform(test_data)\n",
    "\n",
    "    return imputed_train, imputed_test\n",
    "\n",
    "\n",
    "def robust_scaler(train_data, test_data):\n",
    "    '''This scaler removes the median and scales the data according to the quantile range.\n",
    "    The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile\n",
    "    (75th quantile). The scaler is fit on the train dataset and applied to the test data\n",
    "    set to prevent training on the test set.\n",
    "    '''\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(train_data)\n",
    "    scaled_train = scaler.transform(train_data)\n",
    "    scaled_test = scaler.transform(test_data)\n",
    "\n",
    "    return (scaled_train, scaled_test)\n",
    "\n",
    "\n",
    "def pca_algorithm(x_train_scaled, x_test_scaled):\n",
    "    '''This algoritm transforms the feature data to 10 Principal Component Axis.\n",
    "    The PCA is fitted to on the train set and transformed into the testset, to prevent\n",
    "    training on the test set.\n",
    "    '''\n",
    "    pca = decomposition.PCA(n_components=10)\n",
    "    pca.fit(x_train_scaled)\n",
    "    x_train_pca = pca.transform(x_train_scaled)\n",
    "    x_test_pca = pca.transform(x_test_scaled)\n",
    "    return x_train_pca, x_test_pca\n",
    "\n",
    "\n",
    "def scoring(y_true_label, y_prediction):\n",
    "    '''This function turns the stringtype labels into numeric order where LGG = 0 and\n",
    "    GBM = 1. It also calculates different metrics: F1-score, precision, recall and accuracy.\n",
    "    '''\n",
    "    y_prediction = [1 if i == 'GBM' else 0 for i in y_prediction]\n",
    "    y_true_label = [1 if i == 'GBM' else 0 for i in y_true_label]\n",
    "\n",
    "    f_one = f1_score(y_true_label, y_prediction)\n",
    "    prec = average_precision_score(y_true_label, y_prediction)\n",
    "    acc = accuracy_score(y_true_label, y_prediction)\n",
    "    recall = recall_score(y_true_label, y_prediction)\n",
    "    return(f_one, prec, acc, recall)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## The machine learning model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_and_results(data, labels, classifier, parameters):\n",
    "    '''This function splits the data and finds the best hyperparameter per split.\n",
    "    This hyperparameter is applied in a classification on the test set in 10 folds. The accuracy,\n",
    "    F1 score, precision, recall, confusion matrices, true positives and aucs are returned'''\n",
    "    accuracies = []\n",
    "    f1_metrics = []\n",
    "    precision = []\n",
    "    recall_metrics = []\n",
    "    conf_matrix_list = []\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
    "    _, axis = plt.subplots()\n",
    "\n",
    "    # Loop over the folds\n",
    "    for i, (train_index, test_index) in enumerate(cv_10fold.split(data, labels)):\n",
    "\n",
    "        # Split the data\n",
    "        x_train = data.iloc[train_index]\n",
    "        y_train = labels[train_index]\n",
    "\n",
    "        x_test = data.iloc[test_index]\n",
    "        y_test = labels[test_index]\n",
    "\n",
    "        # Preprocessing of data\n",
    "        imputed_train, imputed_test = imputation(x_train, x_test)\n",
    "        scaled_train, scaled_test = robust_scaler(imputed_train, imputed_test)\n",
    "        pca_train, pca_test = pca_algorithm(scaled_train, scaled_test)\n",
    "\n",
    "        # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
    "        grid_search = model_selection.GridSearchCV(classifier, parameters,\n",
    "                                                   cv=cv_10fold, scoring='roc_auc')\n",
    "        grid_search.fit(pca_train, y_train)\n",
    "\n",
    "        # Get resulting classifier with best hyperparameter\n",
    "        clf = grid_search.best_estimator_\n",
    "\n",
    "        # Test the classifier on the test data\n",
    "        predicted = clf.predict(pca_test)\n",
    "\n",
    "        # Scores per fold\n",
    "        f1_metric, prec, acc, recall = scoring(y_test, predicted)\n",
    "        f1_metrics.append(f1_metric)\n",
    "        accuracies.append(acc)\n",
    "        precision.append(prec)\n",
    "        recall_metrics.append(recall)\n",
    "\n",
    "        # Confusion matrix per fold\n",
    "        conf_matrix = metrics.confusion_matrix(y_test, predicted)\n",
    "        conf_matrix_list.append(conf_matrix)\n",
    "\n",
    "        # plot ROC curve per fold\n",
    "        viz = metrics.plot_roc_curve(clf, pca_test, y_test,\n",
    "                                     name='ROC fold {}'.format(i),\n",
    "                                     alpha=0.3, lw=1, ax=axis)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "        print(f'Finished fold: {i+1} of 10')\n",
    "\n",
    "    # Combine accuracy, F1 score, precision and recall of each fold in a dataframe with mean and std\n",
    "    scoring_df = {'mean accuracy': mean(accuracies), 'std accuracy': stdev(accuracies),\n",
    "                  'mean f1': mean(f1_metrics), 'std f1': stdev(f1_metrics),\n",
    "                  'mean precision': mean(precision), 'std precision': stdev(precision),\n",
    "                  'mean recall': mean(recall_metrics), 'std recall': stdev(recall_metrics)}\n",
    "    print(scoring_df)\n",
    "\n",
    "    # Plot combined ROC curves\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    axis.plot(mean_fpr, mean_tpr, color='b',\n",
    "              label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "              lw=2, alpha=.8)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    axis.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                      label=r'$\\pm$ 1 std. dev.')\n",
    "    axis.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "             title=\"Receiver operating curve\")\n",
    "    axis.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Combine results of confusion matrices into one mean confusion matrix\n",
    "    mean_of_conf_matrix = np.mean(conf_matrix_list, axis=0)\n",
    "    conf_matrix_df = pd.DataFrame.from_dict({\n",
    "            'Actual: GBM': mean_of_conf_matrix[0],\n",
    "            'Actual: LGG': mean_of_conf_matrix[1]},\n",
    "             orient='index', columns=['Predicted: GBM', 'Predicted: LGG'])\n",
    "    seaborn.heatmap(conf_matrix_df/np.sum(np.sum(conf_matrix_df)),\n",
    "                    annot=True, fmt='.2%', cmap='Blues')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "source": [
    "## Preprocessing of the raw data\n",
    "\n",
    "The raw data is filtered based on NaN percentage. The boundry for features selection has been set so that the feature is present in 80% of the samples. Furthermore, the label are stored in a seperate array and or popped from the main dataframe. Also the parameters for different classifiers are set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data preprocessing: Drop NaN\n",
    "all_data = load_data()\n",
    "nan_threshold = math.floor(len(all_data)*0.8)\n",
    "all_data = dropnan(all_data, nan_threshold)\n",
    "all_labels = np.array(all_data['label'])\n",
    "all_data.pop('label')\n",
    "\n",
    "# Set hyperparameter window for three classifiers: KNN, RandomForest and Support Vector Machine\n",
    "\n",
    "# KNN, Number of neighbors range from (1,3, ... 27, 29)\n",
    "parameters_knn = {\"n_neighbors\": list(range(1, 30, 2))}\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# RF, Number of trees range from (1,6, ... 46, 51)\n",
    "parameters_RF = {\"n_estimators\": list(range(1, 52, 5))}\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# SVM, Number of neighbors range from (1,6, ... 27, 29)\n",
    "parameters_svm = {\"C\": [0.4, 0.6, 0.8, 1, 1.2, 1.4], \"coef0\": list(range(1, 27, 5))}\n",
    "svm = SVC(probability=True, gamma='scale', kernel='poly')"
   ]
  },
  {
   "source": [
    "## Run Classifier: k-Nearest Neighbor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model_and_results(all_data, all_labels, knn, parameters_knn)"
   ]
  },
  {
   "source": [
    "## Run Classifier: Support Vector Machine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model_and_results(all_data, all_labels, svm, parameters_svm)"
   ]
  },
  {
   "source": [
    "## Run Classifier: Random Forrest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model_and_results(all_data, all_labels, RF, parameters_RF)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd07ee863097085b212576272a85a52ddbd4e70a8985d4d5cdbde132f7673c79314",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}